{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfff8bb",
   "metadata": {},
   "source": [
    "# K Means Clustering and Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c15131",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "![](plots/q2_data_viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9216f9",
   "metadata": {},
   "source": [
    "## K Means Clustering\n",
    "\n",
    "I used the ```scipy.cluster.vq.kmeans2``` class to perform the clustering on the dataset.\n",
    "\n",
    "Since, kmeans2 only returns the clusters and a map to the initial labels is missing, I made an assumption that the left most cluster is ```Ear_left```, the right most cluster is ```Ear_right``` and the last one is the ```Head```.\n",
    "\n",
    "Below are the confusion matrix and the clustering plots\n",
    "\n",
    "![](plots/q2_kmeans_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677936c",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Models\n",
    "\n",
    "Outputs of the Gaussian Mixure Models in the first four iterations\n",
    "\n",
    "![](plots/q2_gmm_0_iter.png)\n",
    "![](plots/q2_gmm_1_iter.png)\n",
    "![](plots/q2_gmm_2_iter.png)\n",
    "![](plots/q2_gmm_3_iter.png)\n",
    "\n",
    "Output after satisfying the convergence criteria (Difference between likelihood < $10^-5$)\n",
    "\n",
    "![](plots/q2_gmm_24_iter.png)\n",
    "\n",
    "Maximization of the likelihood function\n",
    "\n",
    "![](plots/q2_likelihood.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1fbee",
   "metadata": {},
   "source": [
    "## Difference between K-Means and Gaussian Mixture Models\n",
    "\n",
    "* The most important difference between K-Means and Gaussian Mixture Models is hard clustering vs soft clustering\n",
    "    * K-Means algorithm gives a binary output. A point either belongs to a cluster or it does not\n",
    "    * Gaussian Mixture Models give a probability that a point could belong to a cluster. The sum of the probabilities for a point across all clusters should be 1\n",
    "    \n",
    "* K-Means does not account for variance. K-Means clusters form circles unlike Gaussisn PDFs that can account for very elliptical clusters\n",
    "\n",
    "**Conclusion**: Gaussian Mixture Models produce better clusters as compared to K-Means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0230fe2",
   "metadata": {},
   "source": [
    "# Python Code Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ed9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.vq import kmeans2\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    with open(file_name, \"r\") as file:\n",
    "        data = file.read().splitlines()\n",
    "    \n",
    "    # Define a regex pattern to filter out unnecessary lines from the CSV file\n",
    "    pattern = \"^\\d+\\.\\d+ \\d+\\.\\d+ [a-zA-Z]+_?[a-zA-Z]*\"\n",
    "    data = [i for i in data if re.search(pattern, i)]\n",
    "\n",
    "    head_coordinates = np.array([[float(j) for j  in i.split(\" \")[0:2]] for i in data if i.split(\" \")[2] == \"Head\"])\n",
    "    ear_left_coordinates = np.array([[float(j) for j  in i.split(\" \")[0:2]] for i in data if i.split(\" \")[2] == \"Ear_left\"])\n",
    "    ear_right_coordinates = np.array([[float(j) for j  in i.split(\" \")[0:2]] for i in data if i.split(\" \")[2] == \"Ear_right\"])\n",
    "    \n",
    "    return head_coordinates, ear_left_coordinates, ear_right_coordinates, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91edbe43",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e18159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(actual, predicted):\n",
    "    num_labels = len(np.unique(actual))\n",
    "    matrix = np.zeros([num_labels, num_labels])\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        matrix[actual[i], predicted[i]] += 1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists to store coordinates of head, ears\n",
    "\n",
    "head_coordinates, ear_left_coordinates, ear_right_coordinates, data = load_data(\"mickey.csv\")\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.scatter(head_coordinates[:,0], head_coordinates[:,1] , color=\"Blue\")\n",
    "plt.scatter(ear_left_coordinates[:,0], ear_left_coordinates[:,1] , color=\"Red\")\n",
    "plt.scatter(ear_right_coordinates[:,0], ear_right_coordinates[:,1], color=\"Green\")\n",
    "plt.axis(\"equal\")\n",
    "plt.savefig(\"plots/q2_data_viz.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89745e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the coordinated into one list to feed to scipy kmeans algorithm\n",
    "\n",
    "train_coordinates = np.array([*head_coordinates, *ear_left_coordinates, *ear_right_coordinates])\n",
    "\n",
    "centroid, predicted = kmeans2(train_coordinates, 3, minit=\"points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning labels to the predicted classes. Sort the centroids by the left coordinate and assign Ear_left, Head, Ear_right respectively\n",
    "\n",
    "labels_sorted = np.argsort(centroid[:,0])\n",
    "labels_original = [\"Ear_left\", \"Head\", \"Ear_right\"]\n",
    "labels_dict = dict(zip(labels_original, labels_sorted))\n",
    "print(labels_dict)\n",
    "actual = np.array([labels_dict[i.split(\" \")[2]] for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec706f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = generate_confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f89181",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(13,6.5)\n",
    "ear_left_predicted = train_coordinates[predicted == labels_dict[\"Ear_left\"]]\n",
    "head_predicted = train_coordinates[predicted == labels_dict[\"Head\"]]\n",
    "ear_right_predicted = train_coordinates[predicted == labels_dict[\"Ear_right\"]]\n",
    "\n",
    "fig.axes[0].scatter(head_predicted[:, 0], head_predicted[:, 1], color=\"Blue\")\n",
    "fig.axes[0].scatter(ear_left_predicted[:, 0], ear_left_predicted[:, 1], color=\"Red\")\n",
    "fig.axes[0].scatter(ear_right_predicted[:, 0], ear_right_predicted[:, 1], color=\"Green\")\n",
    "fig.axes[0].scatter(centroid[:, 0], centroid[:, 1], color=\"Black\")\n",
    "fig.axes[0].axis(\"equal\")\n",
    "fig.axes[0]\n",
    "\n",
    "fig.axes[1].matshow(c_matrix, cmap=\"gray\")\n",
    "fig.axes[1].set_xticks(ticks=list(labels_dict.values()))\n",
    "fig.axes[1].set_yticks(ticks=list(labels_dict.values()))\n",
    "fig.axes[1].set_xticklabels(labels=list(labels_dict.keys()), rotation=45)\n",
    "fig.axes[1].set_yticklabels(labels=list(labels_dict.keys()), rotation=45)\n",
    "fig.axes[1].set_xlabel(\"Predicted\")\n",
    "fig.axes[1].set_ylabel(\"Actual\")\n",
    "for i in range(len(c_matrix)):\n",
    "    for j in range(len(c_matrix)):\n",
    "        fig.axes[1].text(j, i, c_matrix[i,j], weight=1000, rotation=45, color=\"blue\")\n",
    "fig.savefig(\"plots/q2_kmeans_output.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252864c",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c35130",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLUSTERS = 3\n",
    "NUMBER_OF_ITERATIONS = 20\n",
    "DIMENSIONS = 2\n",
    "\n",
    "head_coordinates, ear_left_coordinates, ear_right_coordinates, data = load_data(\"mickey.csv\")\n",
    "\n",
    "# Concatenate all the coordinated into one list to feed to scipy kmeans algorithm\n",
    "train_coordinates = np.array([*head_coordinates, *ear_left_coordinates, *ear_right_coordinates])\n",
    "\n",
    "NUM_DATA_POINTS = train_coordinates.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08327f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clusters:\n",
    "    \n",
    "    def __init__(self, NUMBER_OF_CLUSTERS, NUM_DATA_POINTS, DIMENSIONS):\n",
    "        self.NUM_CLUSTERS = NUMBER_OF_CLUSTERS\n",
    "        self.NUM_DATA_POINTS = NUM_DATA_POINTS\n",
    "        self.DIMENSIONS = DIMENSIONS\n",
    "        self.centroids = np.zeros([NUMBER_OF_CLUSTERS, DIMENSIONS])\n",
    "        self.covariances = np.zeros([NUMBER_OF_CLUSTERS, DIMENSIONS, DIMENSIONS])\n",
    "        self.mixing_weights = np.zeros([NUMBER_OF_CLUSTERS, 1])\n",
    "        self.cluster_probability = np.zeros([NUM_DATA_POINTS, NUMBER_OF_CLUSTERS])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"There are {self.NUM_CLUSTERS} with centroids at \\n {self.centroids}\"\n",
    "    \n",
    "# Initialise the clusters\n",
    "clusters = Clusters(NUMBER_OF_CLUSTERS, NUM_DATA_POINTS, DIMENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_hot(cluster_assignment):\n",
    "    \"\"\"\n",
    "    Function to generate one hot encoding from the cluster assignment done using K-Means clustering.\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((cluster_assignment.size, cluster_assignment.max()+1))\n",
    "    encoded[np.arange(cluster_assignment.size),cluster_assignment] = 1\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def get_cluster_mean(cluster, cluster_probability):\n",
    "    \"\"\"\n",
    "    Function to calculate the cluster mean parameter.\n",
    "    \"\"\"\n",
    "    cluster_probability = cluster_probability.reshape(-1,1)\n",
    "    coordinates_average = np.multiply(cluster, cluster_probability)\n",
    "    cluster_mean = np.sum(coordinates_average, axis=0)/np.sum(cluster_probability)\n",
    "    return cluster_mean\n",
    "\n",
    "\n",
    "def get_cluster_covariance(cluster, cluster_mean, cluster_probability):\n",
    "    \"\"\"\n",
    "    Function to calculate cluster covariance parameter\n",
    "    \"\"\"\n",
    "    cov = np.zeros([train_coordinates.shape[1], train_coordinates.shape[1]])\n",
    "\n",
    "    for i in range(train_coordinates.shape[0]):\n",
    "        distance_metric = (train_coordinates[i]-cluster_mean).reshape(-1,1)\n",
    "        cov += cluster_probability[i]*np.dot(distance_metric, distance_metric.T)\n",
    "    \n",
    "    return cov/np.sum(cluster_probability)\n",
    "\n",
    "\n",
    "def get_mixing_weights(cluster_probability):\n",
    "    \"\"\"\n",
    "    Function to calculate the mixing weights\n",
    "    \"\"\"\n",
    "    return np.sum(cluster_probability)/len(cluster_probability)\n",
    "\n",
    "\n",
    "def calculate_joint_gaussian(cluster, clusters):\n",
    "    \"\"\"\n",
    "    Function to calculate the joint gaussian PDF of all the clusters\n",
    "    \"\"\"\n",
    "    N = clusters.NUM_DATA_POINTS\n",
    "    gaussian_pdf = np.zeros([N,3])\n",
    "    for j in range(clusters.NUM_CLUSTERS):\n",
    "        for i in range(N):\n",
    "            distance_metric = (cluster[i,:] - clusters.centroids[j]).reshape(-1,1)\n",
    "\n",
    "            # Splitting the numerator into multiple terms for readability\n",
    "            _a = np.dot(distance_metric.T, np.linalg.inv(clusters.covariances[j]))\n",
    "            _num = np.exp(-0.5*np.dot(_a, distance_metric))\n",
    "            _denom = np.sqrt((2*np.pi)**cluster.shape[1]*np.linalg.det(clusters.covariances[j]))\n",
    "            gaussian_pdf[i,j] = _num/_denom\n",
    "    \n",
    "    return gaussian_pdf\n",
    "\n",
    "\n",
    "def compute_expectation(clusters, gaussian_pdf):\n",
    "    \"\"\"\n",
    "    Expectation step:\n",
    "    Calculate the probabilities of each point with respect to the clusters\n",
    "    \"\"\"\n",
    "    # Denominator of expectation step is same for all clusters.\n",
    "    # Compute the denominator\n",
    "    _denom = 0\n",
    "    for i in range(clusters.NUM_CLUSTERS):\n",
    "        _denom += clusters.mixing_weights[i]*gaussian_pdf[:,i]\n",
    "    \n",
    "    for i in range(clusters.NUM_CLUSTERS):\n",
    "        clusters.cluster_probability[:,i] = clusters.mixing_weights[i]*gaussian_pdf[:,i]/_denom\n",
    "        \n",
    "\n",
    "def compute_likelihood(mixing_weights, gaussian_pdf):\n",
    "    \"\"\"\n",
    "    Compute the log likelihood function of the current assignment.\n",
    "    \"\"\"\n",
    "    return np.sum((np.log(np.dot(gaussian_pdf, clusters.mixing_weights))))\n",
    "    \n",
    "    \n",
    "        \n",
    "def assign_clusters(cluster_probability):\n",
    "    \"\"\"\n",
    "    Function to assign clusters based on the maximum probable cluster\n",
    "    \"\"\"\n",
    "    assignment = np.argmax(cluster_probability, axis=1)\n",
    "    assignment_one_hot = generate_one_hot(assignment)\n",
    "    return assignment, assignment_one_hot\n",
    "\n",
    "\n",
    "def plot_clusters(train_coordinates, predicted, centroid, labels_dict, ax):\n",
    "    ear_left_predicted = train_coordinates[predicted == labels_dict[\"Ear_left\"]]\n",
    "    head_predicted = train_coordinates[predicted == labels_dict[\"Head\"]]\n",
    "    ear_right_predicted = train_coordinates[predicted == labels_dict[\"Ear_right\"]]\n",
    "\n",
    "    ax.scatter(head_predicted[:, 0], head_predicted[:, 1], color=\"Blue\")\n",
    "    ax.scatter(ear_left_predicted[:, 0], ear_left_predicted[:, 1], color=\"Red\")\n",
    "    ax.scatter(ear_right_predicted[:, 0], ear_right_predicted[:, 1], color=\"Green\")\n",
    "    ax.scatter(centroid[:, 0], centroid[:, 1], color=\"Black\")\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "    \n",
    "def generate_confusion_matrix(actual, predicted):\n",
    "    num_labels = len(np.unique(actual))\n",
    "    matrix = np.zeros([num_labels, num_labels])\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        matrix[actual[i], predicted[i]] += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(centroid, predicted, data, ax):\n",
    "    labels_sorted = np.argsort(centroid[:,0])\n",
    "    labels_original = [\"Ear_left\", \"Head\", \"Ear_right\"]\n",
    "    labels_dict = dict(zip(labels_original, labels_sorted))\n",
    "#     print(labels_dict)\n",
    "    actual = np.array([labels_dict[i.split(\" \")[2]] for i in data])\n",
    "    \n",
    "    c_matrix = generate_confusion_matrix(actual, predicted)\n",
    "    \n",
    "    ax.matshow(c_matrix, cmap=\"gray\")\n",
    "    ax.set_xticks(ticks=list(labels_dict.values()))\n",
    "    ax.set_yticks(ticks=list(labels_dict.values()))\n",
    "    ax.set_xticklabels(list(labels_dict.keys()), rotation=45)\n",
    "    ax.set_yticklabels(list(labels_dict.keys()), rotation=45)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    for i in range(len(c_matrix)):\n",
    "        for j in range(len(c_matrix)):\n",
    "            ax.text(j, i, c_matrix[i,j], weight=1000, rotation=45, color=\"blue\")\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def plot_gaussians(clusters, ax):\n",
    "    \"\"\"\n",
    "    Function to plot gaussian contours\n",
    "    \"\"\"\n",
    "    x, y = np.mgrid[0:1:.01, 0:1:.01]\n",
    "    pos = np.dstack((x, y))\n",
    "    colors = [\"Reds\", \"Blues\", \"Greens\"]\n",
    "    \n",
    "    for i in range(NUMBER_OF_CLUSTERS):\n",
    "        rv = multivariate_normal(clusters.centroids[i,:], clusters.covariances[i])\n",
    "        pdf = rv.pdf(pos)\n",
    "        ax.contour(x, y, pdf, levels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if initial centroids information is available from the K-Means run. Else run kmeans on the data again to generate the initial clusters\n",
    "\n",
    "if 1: #\"centroid\" not in locals() or \"predicted\" not in locals():\n",
    "    print(f\"Initial cluster information not available. Clustering using K-Means now!\")\n",
    "    centroid, predicted = kmeans2(train_coordinates, 3, minit=\"points\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "clusters.cluster_probability = generate_one_hot(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa67fa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(NUMBER_OF_ITERATIONS, 3)\n",
    "# fig.set_size_inches(20,20)\n",
    "likelihood = []  # Define a list to store all the likelihoods\n",
    "iteration_num = 0  # Initialise the number of iterations to 0\n",
    "\n",
    "while True:\n",
    "# for iteration in range(NUMBER_OF_ITERATIONS):\n",
    "    # Compute the centroids and update the values\n",
    "    for i in range(NUMBER_OF_CLUSTERS):\n",
    "            clusters.centroids[i,:] = get_cluster_mean(train_coordinates, clusters.cluster_probability[:,i])\n",
    "\n",
    "    # Compute covariances and update the values\n",
    "    for i in range(NUMBER_OF_CLUSTERS):\n",
    "            clusters.covariances[i,:,:] = get_cluster_covariance(train_coordinates, clusters.centroids[i,:], clusters.cluster_probability[:,i])\n",
    "\n",
    "    # Compute mixing weights and update the values\n",
    "    for i in range(NUMBER_OF_CLUSTERS):\n",
    "            clusters.mixing_weights[i,:] = get_mixing_weights(clusters.cluster_probability[:,i])\n",
    "\n",
    "    # Calculate Joint Gaussian PDF for the points\n",
    "    gaussian_pdf = calculate_joint_gaussian(train_coordinates, clusters)\n",
    "\n",
    "    # Expectation step\n",
    "    compute_expectation(clusters, gaussian_pdf)\n",
    "    \n",
    "    # Compute the likelihood\n",
    "    likelihood.append(compute_likelihood(clusters.mixing_weights, gaussian_pdf))\n",
    "    \n",
    "    # Get the assignments and plot the clusters\n",
    "    if iteration_num%4 == 0 or iteration_num in range(0,4):\n",
    "        fig, ax = plt.subplots(1, 3)\n",
    "        fig.set_size_inches(12,4)\n",
    "        assignment, _ = assign_clusters(clusters.cluster_probability)\n",
    "        labels_dict = plot_confusion_matrix(clusters.centroids, assignment, data, fig.axes[0])\n",
    "        plot_clusters(train_coordinates, assignment, clusters.centroids, labels_dict, fig.axes[1])\n",
    "        plot_gaussians(clusters, ax=fig.axes[2])\n",
    "        fig.suptitle(f'Plots at {iteration_num} iteration')\n",
    "        fig.savefig(f\"plots/q2_gmm_{iteration_num}_iter.png\", dpi=200)\n",
    "        fig.show()\n",
    "    \n",
    "    if likelihood[iteration_num] - likelihood[iteration_num-1] < 1e-5 and iteration_num > 1:\n",
    "        break\n",
    "    \n",
    "    iteration_num += 1  # Increment the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f539627",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(likelihood)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Log Likelihood\")\n",
    "plt.title(\"Iterations vs Log Likelihood\")\n",
    "plt.savefig(\"plots/q2_likelihood.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47ec5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
